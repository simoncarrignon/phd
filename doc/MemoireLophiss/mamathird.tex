
\chapter{la Robotique Évolutionnaire}\label{ch:RE}

\lettrine[lines=2]{N}{ous} terminerons ce mémoire en décrivant en détails la Robotique \'Evolutionnaire. Nous commencerons par rappeler son histoire et ses influences, puis nous décrirons dans les grandes lignes la méthodologie traditionnelle de la discipline.

Nous verrons ensuite certains problèmes que cette méthodologie implique et introduirons les voies suivies par certains chercheurs pour essayer de les résoudre. Nous insisterons sur l'\emph{\'Evolution Embarquée} \citep{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots} et \emph{dirigée par l'environnement} \citep{bredeche2012environmentdrivendistributedevolutionaryadaptation}, car, et nous verrons pourquoi, ces dernières nous semblent les développements de la Robotique \'Evolutionnaire les plus appropriés pour étudier la biologie.

Nous terminerons ce chapitre en positionnant rapidement la RE vis à vis des approches présentées dans le chapitre précédant.


\section{Histoire et principes}\label{sec:re}
\subsection{Bref Historique}

Comme nous l'avons déjà décrit en introduction, la Robotique Évolutionnaire (RE, en anglais RE, \emph{Evolutionary Robotics}) descend directement de l'Algorithmique Évolutionnaire. Le principe clef est de reprendre <<\,l'outil\,>>, les \emph{recettes} (comme les appelle \cite{godfrey2009darwinian} cf. section \ref{sec:pgs}) de la théorie darwinienne de l'évolution revue et corrigée par les néo-darwiniens et la synthèse moderne, afin de trouver une méthode pour construire automatiquement des robots.
Comme nous l'avons aussi déjà introduit, l'intuition que l'évolution selon Darwin peut s'appliquer à des machines pour leur offrir la complexité et la robustesse nécessaires à leur autonomie dans le monde réel est aussi vieille que l'informatique elle-même, le texte de \cite{turing50computingmachineryintelligence} en faisant foi.

Mais bien que cette intuition était présente alors que l'informatique balbutiait au stade embryonnaire, il a fallu attendre : 1. l'invention de l'Algorithmique \'Evolutionaire (AE, cf. \ref{sec:intro:ae}) pour démontrer le bien fondé et l'utilité de l'application de ces idées à des entités numériques ; et, 2. qu'émerge une nouvelle école de robotique aux fondements théoriques différents de la robotique classique alors en vigueur aux débuts de l'AE, pour que l'intuition de Turing trouve un terrain empirique et théorique fertile à son implémentation.

Nous avons déjà vu en introduction les principes et l'histoire de l'algorithmique évolutionnaire et avant d'en faire de même pour la Robotique \'Evolutionnaire (RE), prenons le temps de dire deux mots sur ce qui nous semble le second prérequis à la naissance de la RE, l'apparition d'une nouvelle école en robotique.

Ce nouveau courant, dont la portée peut en fait être étendue à l'Intelligence Artificielle en général, a opéré un changement conceptuel quasi philosophique à la fin des années 80. Les roboticiens de cette période ont démontré que la voie suivie par l'Intelligence Artificielle traditionnelle de l'époque, fille du computationalisme des années 60, n'était pas la seule possible. Reprenant les travaux de \citet{braintenberg86vehicles} et de certains éthologues, \cite{brooks91intelligencewithoutreason} notamment montra que pour obtenir des comportements efficaces et robustes\footnote{Nous entendons par robuste : peu sensible aux conditions initiales} dans des environnements complexes, la longue computation d'une représentation symbolique du monde n'est pas forcément la meilleure solution pour agir avec justesse et rapidité. Souvent il suffit de construire un système dont les propriétés morpho-physiologiques répondent correctement aux contraintes de l'environnement, capable de s'imbriquer dans une boucle <<\,perception-action\,>> simple et <<\,réactive\,>> (la robotique issue de ces réflexions étant bien souvent appelée <<\,Robotique Réactive\,>>).

Ce changement de perspective paraît <<\,plus en accord avec l'histoire évolutive des organismes\,>> \citep[Brooks dans la préface de ][p. 15]{pfeifer2006howthebodyshapesthewaywethink}. Il débarrasse ainsi l'intelligence de la complexité du computationalisme et permet aux chercheurs en évolution artificielle d'imaginer pouvoir coder simplement des comportements efficaces et intéressants, sans besoin de bases de données gigantesques manipulées par des systèmes experts complexes.

Il est à noter qu'à la même époque les neurones formels, initialement introduits par \cite{mcculloch1943alogicalcideaimmanervacti}, étaient en plein développement. En particulier, au milieux des années 80, \cite{rumelhart1986learninginternalrepresentationsbyerrorpropagation} inventaient un type particulier de réseaux de neurones formels, les perceptrons multicouches. Nous reparlerons en détail de ces réseaux un peu plus tard dans cette partie, notons juste pour le moment que ces outils computationnels, apparus au bon moment, se sont révélés un modèle parfait pour implémenter le paradigme de Brooks, et deviendront un élément central de la robotique évolutionnaire. Leur utilisation et leur principe de fonctionnement (que nous reverrons) les rendent assez simples pour qu'ils puissent être largement utilisés tout en présentant certaines caractéristiques essentielles aux études de RE (nous verrons lesquelles plus tard).

Cette naissance de la Robotique \'Evolutionnaire eu lieu de fa\c{c}on quasi simultanée et en parallèle dans trois universités différentes au début des années 1990. Une en Angleterre (plus précisément dans la ville de Sussex), une aux \'Etats Unis à l'université de Caroline du Sud et l'autre en Suisse, à l'\'Ecole Polytechnique Fédérale de Lausanne (cf la préface de \cite{nolfi00evolrobobiolintetechselfmach} ou encore \citet{harvey97evolutionaryroboticssussexapproach} pour une introduction plus détaillée de cette naissance du point de vu de l'école anglaise).

Dès le début l'application de ces méthodes pour étudier la biologie --application que nous voulons défendre ici, était envisagée par les fondateurs de la discipline. Ainsi, \cite{cliff93explorationsinevolutionaryrobotics} expliquent dès le résumé d'un article d'époque qui passe en revue leurs premières avancées dans le domaine, que si leur objectif premier <<\,est de développer des systèmes de contrôle sensorimoteur pour des robots mobiles, [ils veulent] aussi discuter l'applicabilité de [leur] approche à l'étude des systèmes biologiques.\,>> \citep[p. 73]{cliff93explorationsinevolutionaryrobotics}. De même ils se considèrent plus proche de <<\,la neuroethologie que des neurosciences computationnelles\,>> (\emph{ibid.} p. 74) qui sont la source d'inspiration première de la robotique classique.

Cette proximité avec la biologie se retrouvera tout au long de l'histoire de la Robotique \'Evolutionnaire. Le but avoué étant de développer des techniques automatiques pour <<\,construire des robots autonomes intelligents et comprendre comment les animaux sont <<\,construits\,>>\,>>(\emph{ibid.}, guillemets d'origine) cela a tout de suite positionné la RE comme une discipline très proche de la Vie Artificielle qui était, à l'époque des premiers travaux de Robotique \'Evolutionnaire, en pleine effervescence \citep{langton89alifeiproceedingsfirstinternationalworkshopsynthesissimulationlivingsystems}. Ainsi, contrairement à l'algorithmique évolutionnaire qui a assez vite pris de la distance vis à vis de son inspiration biologique originelle, les buts et directions de la Robotique \'Evolutionnaire sont restés intimement liés à ce désir d'être à la fois un outil \emph{inspiré par} la biologie, mais aussi \emph{inspirant pour} la biologie. Reprenant à leur compte et selon leurs termes ce principe dont nous avons déjà soulevé la formulation par \cite{maynardsmith78optimizationtheoryinevolution} en introduction qui dit que :

\begin{quotation}

   Il y a une similarité entre le problème d'ingénierie de créer un robot autonome fonctionnel amené à agir dans un environnement complexe et bruité et le problème scientifique de proposer un modèle plausible des mécanismes sous-jacents la genèse du comportement adaptatif d'un animal.\\
   \citep[p. 74]{cliff93explorationsinevolutionaryrobotics}

\end{quotation}

De même pour \citet[p. 12-13]{nolfi00evolrobobiolintetechselfmach}, la question principale motivant la RE est de permettre de comprendre :

\begin{quotation}

   Quelles sont les caractéristiques clefs de l'évolution naturelle qui la rendent capable de produire l'extraordinaire variété de formes de vie hautement adaptées présentes sur la planète? Répondre à cette question pourrait améliorer significativement à la fois notre compréhension des systèmes biologiques et notre habilité à concevoir des systèmes artificiels.

\end{quotation}

Assez vite une communauté va se former autour des groupes de Sussex, de l'USC et de l'EPFL. Cette communauté va réunir des chercheurs en Vie Artificielle, en Robotique, en \'Ethologie, en Algorithmique \'Evolutionnaire ou encore en Neurosciences Cognitives. De nombreuses études vont être menées, s'appuyant sur des approches différentes, avec des ambitions différentes, mais ayant toute un ensemble de problématiques et de méthodes similaire. Puis en 2000 paraît le livre <<\,éponyme\,>> \emph{Evolutionary Robotics} \citep{nolfi00evolrobobiolintetechselfmach}. La publication de ce livre quelques années après la première conférence entièrement consacrée au sujet en 1998, peut être perçue comme l'auto-reconnaissance de la Robotique \'Evolutionnaire en tant que discipline à part entière. En publiant cet ouvrage la n'est plus simple sous composante de tel ou tel autre discipline, mais devient une discipline en tant que telle, maîtresse de ses propres buts, utilisant ses propres méthodes.

\subsection{Principes}

Le principe de base de la Robotique \'Evolutionnaire (RE) est exactement le même que celui que nous avons présenté en introduction pour décrire l'Algorithmique \'Evolutionnaire (AE) : appliquer les principes de l'évolution selon Darwin à des artefacts humains (plus précisément numériques dans le cas de l'AE).

Parmi les différences notables (que nous avons déjà soulevées) qu'on peut noter entre AE et RE, les premières à s'imposer sont : l'objet, le du but et l'environnement avec lesquels travaillent les roboticiens. Le but de ces derniers est de construire des robots qui doivent se déplacer de façon tout à fait autonome dans des environnements <<\,réel\,>>, qu'on ne connaît pas forcément à l'avance. Ces environnements sont susceptibles de subir de nombreux changements pendant l'activité du robot, changements qui peuvent même (qu'on peut souhaiter) être produits par le robot lui-même. Les contraintes qui s'appliquent sont donc beaucoup plus proches de celles auxquelles sont soumis les êtres vivants que des solutions et des objets manipulés par l'AE.

Néanmoins une limitation technologique importante, qui diminue de beaucoup l'étendue de l'analogie possible entre RE et biologie est à noter et doit être prise en compte au plus tôt. La grande majorité des travaux, et la quasi totalité des méthodes que nous allons décrire, portent sur le développement par évolution artificielle des éléments responsables du contrôle du comportement des êtres vivants, les régulateurs de la boucle sensorimotrice <<\,perceptions/actions\,>> ---ce qui pourrait correspondre, si l'on poursuit quand même l'analogie, au système nerveux des êtres vivants, dont la partie par l'observateur est ce qu'on pourrait appeler le \emph{comportement} des robots. La morphologie des robots quant à elle n'est en aucun cas modifiée. Elle est fixe et imposée dès le départ par le modèle de robot choisi pour l'étude en question et ne changera pas, si ce n'est à cause de problèmes d'usure.

Hors, dans le monde du vivant, l'évolution du système nerveux est intimement liée à l'évolution de la morphologie des êtres biologiques qu'il <<\,contrôle\,>>. Plus encore, depuis une vingtaines d'années un grand nombre d'études et quasiment toute une école de pensée (souvent désignée par le terme de \emph{embodied cognition} et qui est d'ailleurs elle aussi une descendante direct des changements de perspective en robotique dont nous avons parlé précédemment) tendent à montrer que cette coévolution est essentielle pour qu'émergent les fonctions cognitives <<\,avancées\,>> qu'ont pu développer, par exemple, les poulpes \citep{pfeifer2006howthebodyshapesthewaywethink}. Néanmoins ce découplage de l'évolution du comportement et du corps ne doit pas empêcher d'appliquer les méthodes d'évolution artificielle à l'étude de l'évolution en générale pour autant.

Premièrement, ce découplage n'a pas empêché les chercheurs du domaine de rapidement le cerner comme une limite. Au contraire, nombreuses sont les études en RE et plus largement en AE appliquées à des systèmes électroniques, qui ont mises en avant l'importance du couplage morphologie/contrôle sensorimoteur. Le rôle de ces expériences est très certainement central dans la prise de conscience de l'importance de ce problème chez les acteurs de la communauté. Et ils s'accordent aujourd'hui tous sur le fait que :
\begin{quotation}
   Bien sur, ce n'est pas ainsi que l'évolution naturelle agit. L'évolution ne démarre pas avec un corps donné et ensuite fait évoluer un cerveau pour ce corps ; en revanche, les deux, corps et cerveau, évoluent ensemble au cours du temps. Pour des systèmes artificiels, la capacité de faire évoluer la morphologie et le contrôle neuronal de concert est cruciale si nous voulons exploiter la totale puissance de l'évolution.
   \\\citep[p. 193]{pfeifer2006howthebodyshapesthewaywethink}
\end{quotation}

Ensuite, et fort de cette constatation, de nombreuses tentatives pour pallier ce problème ont été proposées. Parmi les premières et les plus connues il y a les remarquables expériences de \cite{sims1994evolving3dmorphologyandbehaviorbycompetition}. Ce dernier a, avec succès, fait coévoluer morphologies et comportements dans des simulations avec des résultats aussi étonnants que convaincants\footnote{Des vidéos et plus de détails sur ces expériences sont disponibles ici : http://www.karlsims.com/evolved-virtual-creatures.html.}. Ces expériences ont été suivies par celles de \cite{pollack2000thegolemproject} dans lesquelles les auteurs ont voulu donner une forme physique aux simulations de Sims, ou encore dans les travaux de \citet[ch. 6]{pfeifer2006howthebodyshapesthewaywethink}.
Cet effort est toujours à l'œuvre et reste un des objectifs centraux de la discipline (la <<\,synthèses automatique\,>> comme le nomment \cite{doncieux2009exploringnewhorizonsinevolutionqryrobotics}). L'idée est de laisser à l'évolution le soin de modeler un maximum des éléments des agents à concevoir et de minimiser le plus possible l'intervention de l'humain. Cette volonté est très présente dans les nombreuses tentatives de rapprochement de la RE avec les sciences du développement en biologie pour former ce que certains appellent <<\,l'evodevorobo\,>> \citep{bredeche11evolutionaryadaptationpopulationrobots} et qui fait dire à \citet[p. 17]{nolfi00evolrobobiolintetechselfmach} que le <<\,développement est une des issues les plus débattues en robotique évolutionnaire\,>> et qu'en RE :
\begin{quotation}
La direction la plus prometteuse est d'inclure dans le processus évolutionnaire d'autres mécanismes tel que la plasticité ontogénique qui pourrait augmenter le puissance adaptative du processus évolutionnaire sans accroître le rôle du concepteur humain.
\end{quotation}

En dernier point il est à noter que ce découplage n'enlève pas nécessairement la valeur que peuvent avoir certains modèles de RE. Malgré les abstractions qui doivent être faites lors des expériences de RE, si ces dernières présentent certaines caractéristiques essentielles similaires à certaines situations biologiques particulières, la simulation peut apporter des choses sur la compréhension du pendant biologique de l'expérience de robotique. De plus, ce découplage, cette distinction comportement/morphologie que semble imposer la RE est vrai si on considère que l'analogue du <<\,corps\,>> des individus biologiques est la structure matériel du robot et que l'individu artificiel est le couple $(Programme,Robot)$. Hors cette analogie, bien que peu discutée car découlant directement de la façon dont sont implémentés les algorithmes évolutionnaires en RE, n'est peut-être pas la plus adéquate. Elle le semble d'autant moins lorsqu'on considère l'important développement des méthodes de <<\,swarm intelligence\,>> par de nombreux chercheurs de la discipline. Dans ces études les scientifiques font évoluer des populations de robots capables de s'associer, de se spécialiser, et dans lesquels la distinction entre individus/morphologie/robots/populations n'est plus si claire.

Une fois apportées ces précisions essayons de nous pencher plus en détail sur le fonctionnement des algorithmes évolutionnaires utilisés en RE.

Dans sa version la plus classique une expérience de Robotique Évolutionnaire se déroule comme suit \citep[pour certains exemples historiques de la littérature]{nolfi96learning,floreano94automaticcreationofanautonomousagen,jakobi97evolutionaryroboticsandtheradicalenvelopeofnoisehypothesis}:

\begin{inparaenum}[(\itshape 1\upshape)]

D'abord \item une tâche que le robot doit résoudre est définie (prenons par exemple la tâche de ramener un objet dans le coin précis d'une pièce, repéré par une couleur particulière).
	

	
Ensuite \item un certain type de programmes informatiques, de contrôleurs autonomes qui vont s'occuper de gérer le comportement du robot, doivent être choisis.

Ces contrôleur doivent avoir certaines propriétés particulières.
   \begin{inparaenum}[(\itshape a\upshape)]
   En premier lieu \item ils doivent fournir aux robots les capacités (qu'on pourrait dans notre cas qualifier de <<\,cognitives\,>>) nécessaires à l'accomplissement de la tâche. Par exemple : si le robot doit parcourir un labyrinthe complexe dans lequel il doit trouver une sortie, alors le robot doit être capable de mémoriser les lieux qu'il visite. Le contrôleur doit pouvoir offrir et gérer cette mémoire.
       De plus,\item c'est le contrôleur, le responsable du comportement du robot, qui va être soumis à l'évolution. C'est lui qui va <<\,subir\,>> les mécanismes nécessaires à l'évolution. Il va être répliqué, muté, croisé, etc\ldots il faut donc que le contrôleur utilisé puisse supporter ce genre de chose. Tout comme dans le cas du voyageur que nous avons vu dans la partie \ref{sec:intro:vc} où il était possible de représenter la solution par une chaîne de caractères que l'on pouvait aisément muter, croiser, etc\ldots le contrôleur doit présenter des propriétés similaires.
   \end{inparaenum}
   C'est pourquoi une des solutions souvent adoptée par les chercheurs est, comme nous l'avons déjà rapidement sous-entendu, les réseaux de neurones artificiels (\emph{Artificial Neural Network}, RNA en anglais). Nous reviendrons plus en détail sur ces réseaux de neurones un peu plus tard. \label{it:RNA}
Ensuite \item et une fois choisis ces contrôleurs ; une <<\,population initiale\,>> va être générée. C'est à dire, pour le cas d'une expérience classique menée avec des réseaux de neurones artificiels, qu'un nombre, donné \emph{a priori}, d'individus, donc de chaînes d'entiers générés aléatoirement, va être créer.

\item Ces contrôleurs générés aléatoirement doivent ensuite être testés sur les robots. Pour ça, différentes méthodes sont possibles et nous en verrons d'autres, mais la classique et historique méthode des pionniers aux moyens limités (et qui ne possèdent donc qu'un robot) est la suivante. Chaque contrôleur est envoyé sur l'unique robot puis exécuté. Lors de l'exécution du contrôleur un certain nombre de données qui serviront à déterminer le degré de réussite du robot sont enregistrées, puis un autre contrôleur est chargé sur le robot pour être testé à son tour. Pour que la comparaison soit possible il faut évidemment que les conditions initiales soient les mêmes et ainsi, le robot doit être remis à son point de départ et toutes les conditions environnementales réinitialisées à l'identique. Ce travail de test est un travail long, fastidieux, sujet à beaucoup d'erreurs et loin de trouver un équivalent dans le monde biologique. Nous verrons certains méthodes qui contournent ce problème, notamment à travers ce que nous présenterons comme l'Évolution Embarquée (EE, cf \ref{sec:RE:EE}). \label{it:test}

\item Une fois les tests de chaque contrôleur terminés une mesure de leur réussite doit être faite, pour qu'une comparaison qualitative entre les différents programmes puisse avoir lieu. C'est ce qu'il est convenu d'appelé le \emph{fonction fitness}.  Cette mesure est un calcul qui va nous offrir le degré d'adaptation, donc la fitness du contrôleur, par rapport à la tâche à accomplir. En général un ensemble de variables (environnementales, <<\,physiologiques\,>>) enregistrées pendant l'expérience vont être utilisées pour ce calcul. Par exemple, dans le cas de notre balle devant être ramenée dans un coin de labyrinthe, une bonne mesure pourrait être la distance restante entre la balle et l'objectif que l'on pourrait pondérer par la vitesse et/ou la distance mise pour amener la balle à cette endroit.
\item En fonction des résultats, un certain nombre de contrôleurs vont être sélectionnés, via par exemple ce qu'il est convenu d'appelé la roulette proportionnée\footnote{Dans la roulette proportionnée les individus sélectionnés vont l'être de sorte que plus les individus ont une fitness élevée plus ils ont de chance d'être sélectionnés. Ainsi on aura en moyenne les meilleurs individus dans les générations suivantes sans pour autant empêcher les individus les moins bons de transmettre leurs caractéristiques.}. Après l'étape de sélection \item on va muter et croiser les <<\,solutions\,>>, les <<\,individus\,>> pour en obtenir de nouveaux, puis les nouvelles solutions constitueront une nouvelle génération et l'expérience pourra repartir en 4.
\end{inparaenum}

La suite d'instructions que nous venons de décrire est un algorithme évolutionnaire du même type que ceux pouvant servir à résoudre le problème du voyageur de commerce que nous avions vu en introduction. Appliqué à la robotique ils sont le cœur de la RE.

Évidement ce schéma, fortement inspiré de la biologie, peut-être raffiné et complexifié à loisir. Chaque étape peut être pensée et réalisée de multiples façons. Certaines de ces étapes vont poser plus de problèmes que d'autres et les résultats obtenus à l'issu de l'exécution de l'algorithme dépendront beaucoup du choix fait à chacune des ces étapes. Nous avons déjà suggéré que le type de contrôleurs utilisés pouvait faire l'objet de ce genre de choix, il en est de même pour la façon de calculer la fitness, le type et le nombre de robots utilisés, l'utilisation de la simulation ou encore la manière de croiser et muter les individus. Tous ces paramètres sont autant d'autres éléments qui peuvent varier d'une étude à l'autre. La littérature abonde sur les pourquoi et comment choisir ces paramètres et nous ne pouvons que vous conseiller de voir \cite{nolfi00evolrobobiolintetechselfmach} pour avoir de plus amples informations sur le sujet. Dans le cadre de ce travail, après avoir décrit un peu plus en détail les contrôleurs les plus utilisés, à savoir les réseaux de neurones artificiels, nous verrons un certain nombre de ces choix méthodologiques. Notamment certains qui ont permis de dépasser des obstacles sur lesquels buttait la RE et qui nous semblent beaucoup plus pertinents compte tenu du cadre dans lequel nous souhaitons utiliser la RE, à savoir l'étude de la théorie de l'évolution.


\subsection{Les réseaux de neurones artificiels}\label{sec:RNA}
Comme nous l'avons annoncé au point \ref{it:RNA} de la description de l'algorithme évolutionnaire classiquement utilisé en RE, la plupart des chercheurs du domaine utilisent des réseaux de neurones artificiels.

Un réseau de neurones artificiels est un concept mathématique qui permet de relier des variables d'<<\,entrée\,>> à des variables de <<\,sortie\,>>. Plus explicitement, suivant une vague analogie avec la biologie, un neurone va recevoir une ou plusieurs données en entrée, qui pourront être fournies par l'environnement ou par d'autres neurones et va s'activer ou non en fonction des valeurs d'entrées et d'une fonction d'activation interne au neurone. À l'intersection entre les neurones (ou entre un neurone et un capteur) sont présentes des <<\,synapses\,>>. Ces synapses possèdent un poids, souvent susceptible de varier au cours de la vie d'un agent (c'est la base de l'<<\,apprentissage\,>>).

Sans nous attarder trop sur les détails de ces réseaux de neurones artificiels, rappelons rapidement que ceux-ci reprennent des concepts développés par \citep{mcculloch1943alogicalcideaimmanervacti} et sont faits en superposant des <<\,couches\,>> de neurones formels (les sorties des neurones des premières couches serviront d'entrée pour les neurones des couches suivantes). En règle général, il est fréquent d'utiliser un type particulier et bien connu de neurones formels : les perceptrons. La mise en réseaux de ces perceptrons, dans ce qu'il est convenu d'appeler par le terme technique des Perceptrons Multi-Couches (PMC, ou MLP pour \emph{Multi-Layer Perceptron} en anglais) offre une solution aux chercheurs en RE avec plusieurs avantages qui en fait le candidat idéal des expériences évolutionnaires. Premièrement, il va être possible de relier les entrés du PMC aux différents capteurs du robots (capteurs de vitesse, infra-rouge, ultra-son, caméras, thermomètres, gyroscopes) ainsi que les sorties sur les <<\,effecteurs\,>> du robot (moteurs, émetteurs lumineux). Ensuite, pour peu qu'on construise ces réseaux de façon adéquate et qu'on leur fournisse des règles pour le faire, ils vont pouvoir être soumis à un apprentissage \citep[p. 30-39]{nolfi00evolrobobiolintetechselfmach}. Cet apprentissage peut être mené de différentes façons. Pendant la ``vie\footnote{Ce qu'on désigne en général par la <<~vie~>> du robot est la période pendant laquelle le robot est testé, ce qui correspondrait à l'étape \ref{it:test} de l'algorithme évolutionnaire décrit avant}'' du robot ou pendant une phase spécifique d'apprentissage. Ces méthodes offrent au robot une <<\,mémoire\,>> et donc la possibilité pour celui-ci de résoudre des tâches plus complexes. Pour terminer avec ce qui nous semble être les principaux atouts des réseaux de neurones artificiels, ces derniers peuvent être très simplement représentés en résumant chaque neurone par le poids de ses <<\,synapses\,>>, la fonction d'activation et les règles d'apprentissage dont il va se servir. Ainsi, ce qui sera considéré comme notre <<\,individu\,>>, soumis à l'évolution, sera une chaîne de nombres, codant pour des poids et des fonctions mathématiques qui seront utilisés dans un Perceptron Multi-Couches conçu pour contrôler un robot.

De façon plus exhaustive et détaillée que ce que nous venons de faire, \citet[p. 39]{nolfi00evolrobobiolintetechselfmach} listent six caractéristiques indépendamment susceptibles de justifier l'emploi des RNA.
\begin{enumerate}
   \item Un \emph{espace de recherche lisse} : ce qui signifie qu'un changement léger dans les paramètres du réseau de neurones aboutira à un changement léger dans le comportement du robot. Ce n'est pas exactement le paramètre C de PGS que nous avons évoqué la section \ref{sec:pgs} puisque la fitness n'entre pas directement en compte. Mais comme cette elle en est une composante certaine, d'autant plus que la fitness des robots est souvent assez directement corrélée à leur comportement. Il est intéressant de noter comme les roboticiens ont réalisé l'importance de cette condition pour que l'évolution soit possible.
   \item Les réseaux de neurones permettent d'ajuster une certaine \emph{granularité}: on peut, dans l'algorithme évolutionnaire mis en place, choisir de prendre en compte et faire évoluer uniquement les poids des neurones ou des groupes de neurones.
   \item Ils peuvent montrer \emph{différents niveaux d'adaptation} : phylogénétiques (évolution du poids des synapses au cours des générations), développementaux (maturation des connexions entre les neurones à l'initialisation des robots), ontogénique (apprentissage par renforcement ou autre avec modification des poids synaptiques au cours de la vie du robot).
   \item Ils offrent une \emph{correspondance directe entre senseurs et effecteurs} : les réseaux de neurones peuvent sans problème recevoir un signal d'entrée analogique continue depuis les capteurs et délivrer un signal discret ou continu aux moteurs selon les besoins.
   \item Ils sont relativement robustes au bruit. Même si les signaux délivrés par les capteurs sont bruités, comme les données sont intégrées par des fonctions d'activations qui somment de nombreuses entrées pondérées, ils sont peu sensibles aux oscillations dues au bruit d'une entrée.
   \item Ils sont une métaphore biologiquement plausible des mécanismes qui supportent les comportements adaptatifs. Ils se présentent donc comme un choix naturel pour qui veut comprendre et reproduire les comportements biologiques. \\
       \citep[Plus ou moins librement adapté de ][p. 39 les emphases ont toutes été ajoutées]{nolfi00evolrobobiolintetechselfmach}
\end{enumerate}
\section{Challenges et méthodes alternatives, \'Evolution Embarquée}\label{sec:RE:EE}
\subsection{Challenges et obstacles}\label{sec:RE:EE:obs}
Mais comme nous l'avons évoqué, certaines étapes présentent des difficultés et les expériences en Robotique \'Evolutionnaire font face à de nombreux obstacles. \cite{mataric96challengesinevolvingcontrollersforphysicalrobots} essayaient déjà de les lister dans un article des débuts de la RE. Nous allons essayer d'en illustrer quelques- uns en reprenant l'exemple d'AE que nous avons esquissé dans la section \ref{sec:re}.

D'abord, pour tester les contrôleurs générés aléatoirement (dans le cas où un unique robot est utilisé pour l'expérience), il faut : transférer un contrôleur sur le robot, démarrer le robot, enregistrer des observations, arrêter le robot et recommencer la manœuvre avec un nouveau contrôleur. De plus il faut veiller qu'à chaque nouveau test les conditions expérimentales soient strictement les mêmes. Le robot doit donc être replacé et les variables de l'environnement ré-initialisées de sorte à ce que tout soit le plus proche de leur état d'origine.

Dans les expériences traditionnelles des débuts tout était fait manuellement par l'expérimentateur. Ainsi le chercheur va prendre son robot, charger le programme à tester à l'intérieur, poser le robot à un point précis dans l'environnement de test, lancer le programme de contrôle, attendre le temps souhaité, arrêter le robot et ré-initialiser l'environnement, replacer le robot et recommencer autant de fois qu'il y a d'individus. Le tout multiplié par le nombre de générations nécessaires à l'émergence de solutions acceptables.

Hors, pour que l'évolution soit efficace et l'expérience intéressante il faut que les populations qui vont évoluer aient un maximum d'individus. Dit autrement il faut tester un grand nombre de contrôleurs sur le robot pour avoir des chances d'obtenir des résultats intéressants. Si l'on considère l'expérience de l'arène de tout à l'heure, et que l'action de prendre le robot, le tester, l'arrêter et charger un nouveau contrôleur prend 5 minutes, qu'on teste cet expérience avec 100 individus sur 10 générations et il faut déjà 83 heures d'expériences. Puisqu'en général l'intérêt des ces expériences est d'essayer l'évolution en faisant varier différents paramètres, si le chercheur veut tester 2 paramètres pouvant prendre trois valeurs différentes (ce qui est très peu), il faut alors 747 heures d'expériences.

Pour pallier ce problème la solution qui est souvent adoptée est d'accélérer le processus en simulant l'évolution des contrôleurs sur ordinateur. Ainsi, des simulateurs sont utilisés, qui recréent l'environnement de l'expérience et permettent de tester les contrôleurs dans des robots virtuels. Le problème lorsque la simulation est utilisée est que les solutions trouvées ne sont jamais parfaitement adaptées à l'environnement réel. Une seconde phase d'évolution est alors souvent nécessaire, pour franchir ce que les chercheurs appellent le <<~\emph{reality gap}~>> et ajuster les contrôleurs aux contraintes physiques. Ce n'est qu'après cette étape que les solutions obtenues par simulation peuvent être utilisables sur robots réels.

\cite{mataric96challengesinevolvingcontrollersforphysicalrobots} soulèvent ces deux problèmes dans leur article, à savoir :
\begin{inparaenum}
\item la lenteur que l'évolution sur des robots réels et
\item les problèmes liés à l'utilisation des simulations
\end{inparaenum}. Mais ils ne s'arrêtent pas à ceux-ci et en listent d'autres. Ils notent, par exemple, les problèmes liés au nombre d'évaluations nécessaires des solutions : combien de fois doit-on évaluer un robot avant d'être sur que sa valeur de fitness soit la bonne? Dans le même registre, ils évoquent les problèmes liés à la conception de la fonction fitness, qui est la fonction qui va donner un score à chaque individu après leur évaluation. Comment la concevoir pour qu'elle réponde aux attentes et que l'algorithme évolutionnaire puisse trouver une solution sans que construire cette fonction soit trop complexe et que se dissolve un des intérêts des méthodes par évolution, à savoir, limiter l'intervention humaine?

Ce problème des fonctions fitness est beaucoup discuté dans la littérature de RE et revêt pour nous un intérêt particulier. Nous allons nous arrêter dessus quelques lignes.

La question principale est de savoir comment construire un outil pour calculer le ``degré de qualité'' d'un robot par rapport à un objectif visé. Replacé dans le cadre de notre exemple où les robots doivent pousser des objets vers une zone, il s'agit de trouver une façon de classer les comportements de sorte que ceux qui permettent aux robots de rapprocher les objets de l'objectif soient en tête. On pourra, par exemple, prendre à la fin de l'évaluation, la distance moyenne des objets à déplacer par rapport au but et dire que plus cette distance est faible, plus les robots auront un score élevé.

Mais si l'on implémente cette contrainte tel quelle, au début de l'expérience, pendant les premières générations, un robot qui ne fait rien aura un meilleur score qu'un robot qui bouge beaucoup en déplaçant les objets et en les éloignant. Hors, il faut d'abord que certains robots soient capables de déplacer les objets (même en les éloignant), avant que la sélection ne puisse favoriser ceux qui les rapprochent du but de ceux qui ne les rapprochent pas\footnote{L'évolution pourrait probablement prendre d'autres chemins pour faire évoluer les comportements voulus mais pour les besoins de l'exemple et pour que ce dernier reste simple nous nous limiterons à cette éventualité.}. Il faut donc trouver une astuce pour encapsuler ces étapes dans la fonction fitness.

Généralement les expérimentateurs décomposent la fonction en y rajoutant des éléments. Ils vont par exemple décider d'augmenter \emph{aussi} le score des individus qui se déplacent beaucoup. Encore que cet ajout va engendrer d'autres problèmes. En effet, un robot qui se déplace beaucoup en faisant des tours sur lui-même aura plus de points qu'un individu qui avance par à coup en ligne droite pour atteindre son but. Là encore les chercheurs vont devoir rajouter un élément et récompenser les individus qui se déplacent beaucoup \emph{en faisant le moins de virage possible}\footnote{Cette mesure s'obtient facilement en calculant la différence de vitesse entre les deux roues : si les deux roues tournent à la même vitesse alors le robot avance droit, sinon, plus la différence est élevée, plus le robot tourne.}. Et ainsi de suite, la fonction fitness pourra être affinée et décomposée en sous éléments. Mais plus le chercheur veut décomposer ce problème et plus il doit le connaître \emph{a priori} et savoir comment le résoudre. Autant de contraintes que devaient affranchir les méthodes par évolution.

En regardant de plus près ces questions de fitness et de définir des ``degrés de qualité'' sont des questions très proches de celles que se posent les biologistes.
On pourrait traduire <<~construire une fonction fitness~>> en termes biologiques et dire que c'est <<~construire l'outil pour aider les populations à gravir le paysage adaptatif dans des directions voulues~>>. Les degrés de qualité ne sont en réalité que le pendant technologique des degrés d'adaptation des êtres vivants.
%C'est en quelque sorte construire les remontées mécaniques des sommets de Wright. Mais tout comme les remontées mécaniques dénaturent les montagnes, et n'amènent finalement que vers d'autres remontées en acier gris, des restaurants d'altitude pleins de touristes et des étangs glacés jonchés de sachets plastiques, et loin donc, de là où la beauté de la nature atteint vraiment des sommets, les fonctions fitness de RE peuvent aussi tromper les systèmes artificiels.

Ainsi comprendre comment faire évoluer des artéfacts complexes et quelle direction donner à l'évolution pour y arriver, revient à comprendre comment les phénomènes évolutifs modifient les phénotypes et génotypes des êtres vivants et comment, de ces modifications, peut émerger la complexité. Avancer dans la compréhension du premier problème permettra d'avancer dans la compréhension de l'autre et \emph{vice-versa}.
Tout comme les paysages adaptatifs de Wright ont offert un modèle graphique permettant aux biologistes de réfléchir aux dynamiques évolutives, réfléchir aux fonctions fitness que manipulent les roboticiens permet de comprendre comment il est possible de \emph{se mouvoir sur} et de \emph{déformer} ces paysages. La robotique évolutionnaire et ses fonctions fitness (que la RE a dérivé de ses inspirations biologiques), offrent un modèle physique pour illustrer les résultats de ces mouvements adaptatifs.

Selon nous ces questions cristallisent certains problèmes majeurs que rencontrent roboticiens \emph{et} biologistes. Elles nous paraissent en ce sens emblématiques des points sur lesquels l'approche des uns peut apporter beaucoup à l'approche des autres, \emph{sans qu'il n'y ai de sens privilégié à cet échange}.

\cite{mataric96challengesinevolvingcontrollersforphysicalrobots} soulèvent encore d'autres problèmes, comme ceux liés à la nécessité d'encoder les comportements de sorte que les algorithmes évolutionnaires puissent les manipuler (ce que les Réseaux de Neurones Artificiels offrent en partie; cf \ref{sec:RNA}). Ils parlent aussi des problèmes liés à l'explosion combinatoire des tests à effectuer si les expérimentateurs veulent essayer de nombreux paramètres, des problèmes liés à l'usure des robots ou encore à la nécessité de recharger ces derniers en énergie (\emph{ibid.} p.~75-81).  Nous avons aussi déjà parlé, dans la section précédente, des problèmes liés au fait que l'évolution ne concerne que le comportement et avons déjà souligné quelques pistes suivies pour les résoudre, et il y a encore beaucoup d'autres problèmes connus que partagent les méthodes d'AE. Nous nous arrêterons donc là pour les limites et challenges rencontrés par la RE.
Dans la suite de cette partie, nous allons présenter des approches particulières de la Robotique \'Evolutionnaire, qui permettent de surmonter certains obstacles cités précédemment tout en renforçant la proximité avec l'étude du vivant qui est au c{\oe}ur de notre réflexion, et qui nous paraissent les modèles de choix pour étudier la biologie.

\subsection{\'Evolution Embarquée}
Dans un premier temps, \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots} ont proposé de changer l'algorithme évolutionnaire de base pour développer ce qu'ils ont appelé <<~l'\'Evolution Embarquée~>> (EE, \emph{Embodied Evolution} en anglais). Dans l'article qui pose les bases de ce principe ils expliquent qu'avec cette EE ils souhaitent :
\begin{quote}
   [qu'] il n'y ai plus d'interventions humaines, que ce soit pour évaluer, reproduire ou repositionner les robots pour les nouveaux tests.\\
   \citep[p.~1]{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots}
\end{quote}
Ces interventions, la RE traditionnelle a du mal à s'en passer.

Partant de ce postulat, ils définissent l'\'Evolution Embarquée comme:
\begin{quotation}
   L'évolution se déroulant au sein d'une population de robots réels dans laquelle l'évaluation, la sélection, la reproduction sont supportés par et entre les robots, d'une façon distribuée, asynchrone et autonome.\\
   \citep[p.~2]{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots}
\end{quotation}

Si les auteurs proposent l'EE comme alternative c'est que cela permettrait selon eux de réaliser trois objectifs :
\begin{enumerate}
\item Concevoir une expérience de \emph{Vie Artificielle},
\item proposer une méthodologie en RE et
\item permettre d'effectuer des tâches collectives.
\end{enumerate}

Et si ils insistent sur cette volonté de rapprocher l'RE des expériences en Vie Artificielle c'est que :
\begin{quote}
   Dans l'évolution naturelle les mécanismes adaptatifs sont totalement décentralisés et distribués : l'évaluation est implicite et la reproduction est menée de façon autonome par les agents de la population. (\emph{ibid.} p.~2)
\end{quote}
Hors ce n'est pas le cas en RE, et ainsi lui font défauts les
\begin{quote}
   propriétés distribués et autonomes de l'évolution naturelle.(\emph{ibid.} p.~2)
\end{quote}

Pourtant ces propriétés, bon nombre d'expériences de Vie Artificielle les implémentent pour essayer de les étudier. Voila pourquoi les auteurs veulent concevoir une expérience de RE comme une expérience de VA. Pour eux, amorcer un tel rapprochement permettrait de dépasser certaines des limites actuelles de la RE. De plus, implémenter une évolution autonome et décentralisée fournirait à la RE les clefs pour qu'elle explore l'univers des tâches que l'on ne peut résoudre que collectivement, dans lesquelles des sous groupes doivent se spécialiser ou pour lesquelles de nombreuses interactions inter-agents sont nécessaires. Ceci ouvrirait les portes aux recherches sur les colonies d'individus, la \emph{swarm intelligence} \citep{garnier2007biologicalprincipeswarmintelligence} et l'étude des organismes multicellulaires et de la spécialisation.

L'idée est donc de proposer une Robotique \'Evolutionnaire alternative dans laquelle l'évolution serait \emph{embarquée} directement sur les robots, de façon totalement autonome, asynchrone et décentralisée.

Pour illustrer leur proposition les auteurs décrivent une expérience dans laquelle ils implémentent leur propre version de cette évolution embarquée. Cette expérience reprend un algorithme génétique dans lequel les ``individus'' qui évoluent sont des réseaux de neurones artificielles. Les génomes, qui vont être mutés et reproduits, sont donc des chaînes qui encodent une représentation de ces réseaux de neurones (cf. partie \ref{sec:RNA}).

D'abord la fitness des individus, ou au moins une valeur qui l'approxime, doit pouvoir être mesurée directement sur les robots pour garantir l'autonomie du processus. Généralement dans une expérience traditionnelle de RE cette autonomie n'est pas respectée. C'est l'expérimentateur ou un ordinateur central qui est en charge de calculer la fitness de chaque individu. Ici, un mécanisme embarqué sur les robots, capable de s'occuper de cette mesure doit être mis en place. Ce mécanisme peut être soit implicite, auquel cas la capacité de survivre et de se reproduire du robot est directement corrélée à sa fitness (sa survie et sa reproduction dépendront directement de sa capacité à résoudre la tâche), soit explicite, dans ce cas un mécanisme embarqué sur le robot spécialement dédié à cette tâche permet de déterminer la fitness en fonction de données qui lui sont accessibles.

Dans les expériences les auteurs proposent de mixer les deux en implémentant un concept d'énergie. Cette énergie le robot va l'obtenir en résolvant la tâche (dans ce cas précis le robot doit se rapprocher d'une source lumineuse). Lorsque le robot a de l'énergie (signe qu'il a réussi au moins une fois la tâche), il va pouvoir se reproduire à un rythme plus élevé que lorsque il n'en a pas. Cette ``énergie'' (qui n'a rien à voir avec l'énergie utilisée par les robots pour actionner leurs moteurs\footnote{Pour supprimer le problème du réapprovisionnement en énergie des robots, les auteurs ont mis en place un dispositif \emph{spécifique} aux besoins de l'expérience. Ils ont construit une dalle électrifiée permettant au robot, via une coque métallique conçue dans cet optique, de recharger leur batterie en continue.}) les auteurs insistent sur le fait que ce n'est pas directement la fitness des individus. Par exemple, la performance du contrôleur présent précédemment, impact sur la jauge d'énergie. Ainsi alors que le nouveau génome n'a peut-être pas encore eu le temps de faire ses preuves il sera transis même s' il n'a pas permis au robot d'atteindre la lumière. C'est pourquoi nous reprendrons la terminologie des auteurs et continuerons de parler de l'énergie plutôt que de la fitness.

La reproduction, qui est un autre élément important de l'évolution, doit elle aussi être assurée de façon autonome et distribuée parmi les robots. Comme il n'est pas possible de créer des nouveaux robots de toutes pièces, il faut réutiliser des robots déjà présents dans la population. Une solution, que décrivent les auteurs, est de, plutôt que prendre deux génomes que l'on croise pour obtenir un nouvel individu, réécrire le génome du parent avec la fitness la plus basse en prenant des morceaux de génome du parent avec la fitness la plus élevée. Plutôt que d'avoir une reproduction sexuée classique où deux individus donnant naissance à un seul, il y a un ``transfert'' de l'information d'un individu à un autre, un peu comme ce que peuvent faire les bactéries avec leurs transferts horizontaux.

Pour leur expérience les auteurs reprennent cette idée en la précisant et en la modifiant un peu : chaque robot va émettre son génome, légèrement muté, en continue. Comme nous l'avons déjà dit ce taux d'émission sera proportionnel au taux d'énergie du robot et donc à sa capacité à résoudre la tâche. Tous les robots qui seront dans le périmètre d'émission du robot émetteur pourront recevoir le génome et choisir d'autoriser le génome reçut à écraser son propre génome. Cette ``autorisation'' de changer le génome se fera en fonction de l'énergie du robot récepteur. Plus l'énergie du récepteur sera élevée plus faible sera la probabilité qu'un autre génome le remplace.

Cette méthode permet aux auteurs de faire évoluer des réseaux de neurones artificiels pour contrôler des robots capables de se diriger vers la lumière. Les résultats obtenus sont intéressants car 1/ ils sont plus efficaces que des contrôleurs conçus manuellement par les auteurs, 2/ ils présentent des comportements assez contre intuitifs qui exploitent très bien les contraintes physiques du monde et l'architecture matérielle des robots.

Néanmoins \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots} admettent que si leur but premier, qui était avant tout la curiosité de voir si un tel système pouvait fonctionner ``par principe'', a été atteint, la méthode, en tant que méthode d'ingénierie de Robotique \'Evolutionnaire reste à améliorer. Dans un premier temps les résultats ne portent que sur des tests qui sont déjà bien connus en robotique et résolvables via d'autres méthodes moins complexes à mettre en {\oe}uvre, ensuite car l'application de l'EE sur des populations de robots engendre de nouveaux problèmes liés à l'interaction de nombreux robots entre eux. Ces problèmes sont autant de nouveaux problèmes à régler qui n'existent pas dans la RE traditionnelle où chaque contrôleur est testé sur un unique robot.

Cela reste pourtant selon nous une étape importante vers un rapprochement de la RE et de la biologie. Les obstacles auxquels font allusions les auteurs sont plus technologiques que conceptuels ; et n'enlèvent rien à la valeur théorique de cette expérience et aux différentes voies de recherche qu'elle inaugure.

\subsection{\'Evolution Dirigée par l'Environnement, \'Evolution \emph{<<~open ended~>>}}

Plus récemment \cite{bredeche11mcmds} (ainsi que de façon à peu près similaire : \cite{trueba11taskdrivenspeciesevolutionaryroboticteams}) reprennent l'idée de \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots} pour proposer leur développement du concept d'\'Evolution Embarquée. Leur démarche se veut encore plus proche des phénomènes naturels (et donc de la vie artificielle). Ils justifient le besoin de cette proximité car elle permet de concevoir :
\begin{quotation}
   des agents physiques autonomes [\dots] (ex : des robots autonomes), faisant faces à des environnements inconnus et/ou dynamiques. Cette classe de problèmes apparaît typiquement lorsque l'environnement demeure inconnu du concepteur humain jusqu'à ce que la population soit opérationnelle dans la situation réelle, ou lorsque l'environnement est connu pour changer pendant l'opération, sans qu'aucune indication ne soit donnée sur le moment et la manière dont ces changements impacteront les stratégies misent au point pour survivre.
   \\\citep[p.1]{bredeche11mcmds}
\end{quotation}

Selon eux, et reprenant en ce sens \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots}, pour obtenir de tels résultats l'évolution doit se faire de façon décentralisée, entre les robots et sans aucune intervention extérieure. Tout comme cela peut être le cas chez les êtres vivants. Ils insistent sur le fait que la fitness ne doit pas être simplement implicite (terme sujet à de nombreuses confusions) mais \emph{dirigée par l'environnement}. \'A l'instar de l'évolution naturelle, c'est de l'interaction entre les robots et leur environnement que doivent émerger les contraintes qui vont, ou non, permettre aux individus de survivre. Appliquer une pression de sélection déterminée par une \emph{fonction fitness} fixée \emph{a priori}, c'est avoir une évolution \emph{dirigée vers un objectif} et cela pose de nombreux problèmes et implique certains pré requis qui limitent beaucoup le champ d'action de l'évolution artificielle. C'est ce que ne veulent pas les auteurs et c'est pourquoi ils souhaitent une évolution \emph{dirigée par l'environnement} et non \emph{dirigée vers un but} ce que \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots} ne proposent pas.

Les problèmes que posent cette évolution dirigée par un objectif sont bien connus des chercheurs en RE et en AE, et de nombreuses autres solutions alternatives sont proposées et étudiées \citep{lehman10efficientlyevolvingprogramsthroughsearchnovelty,lehman2011abandoningobjectivesevolutionthroughthesearchfornoveltyalone,risi2009hownoveltysearchescapesthedeceptivetrapoflearningtolearn,mouret2012encouragingbehavioraldiversityinevolutionaryrobotics}. Ce problème pourrait d'ailleurs très bien être mis en parallèle avec un autre débat en biologie : nous avons rapidement évoqué la diffusion des idées de théorie de l'information et d'optimisation en biologie, initiée entres autres par \cite{maynardsmith78optimizationtheoryinevolution}. Les limites de cette approche ont très vite été pressenties par les biologistes et sont très proches de celles que rencontrent les chercheurs en AE et RE. La reprise par les biologistes de cette idée que les êtres vivants étaient une somme d'optimisations et que l'évolution pouvait être comprise ainsi a été sujet à de nombreux débats.
Ainsi, \cite{gould1979spandrelssanmarcopanglossianparadigmcritiqueadaptationistprogramme}, mettaient déjà en garde sur la possibilité de

\begin{quote}
   [\ldots] découper l'organisme en ``traits'' unitaires et de proposer une histoire adaptative pour chacun considéré séparément.``
\end{quote}
Ce que ce retrouve à faire les chercheurs en RE lorsqu'ils construisent leurs fonctions fitness.

\'A la lumière des problèmes théoriques et pratiques soulevés par ces fonctions fitness, on comprend pourquoi \cite{bredeche2012environmentdrivenopenende} ont préféré choisir de suivre la voie explorée parallèlement par de nombreux chercheurs en vie artificielle : la voie de l'évolution \emph{open-end}~\citep{ray91anapproachtothesynthesisoflife,adami94evolutionarylearninginthe2Dartificiallifesystemavida}. Dans le cadre de cette évolution \emph{open-ended}, qui pousse plus loin encore la bio-inspiration, il n'est plus question de \emph{sélectionner} en attribuant une qualité aux individus observés. L'unique but est d'\emph{observer} l'évolution des individus au sein de l'environnement. D'observer les réactions du système, selon les contraintes de l'environnement, les capacités des agents, sans intervenir d'aucune fa\c con.

Il est d'ailleurs important de noter que cette étude de l'évolution \emph{open-ended} est partie intégrante des grands défis des chercheurs en Vie Artificielle~\citep{bedau2000openproblemsinartificiallife}. Dans ce domaine et à la différence de l'AE et la RE les chercheurs font plus souvent passer l'évolution du statut d'outils à celui d'objet d'étude. Et c'est ce retournement que veulent amorcer \cite{bredeche11mcmds}.

Pour les théoriciens de la Vie Artificielle le but est de trouver: (a) \emph{ce qui est inévitable dans l'évolution de la vie},(b) \emph{les caractéristiques communes à tous les processus évolutionnaires}, et pour finir : (c) \emph{trouver les conditions minimales d'évolution pour passer de systèmes répondants uniquement à des environnements simples et spécifiques, à des systèmes capables de généraliser et répondre dans de multiples environnement}~\citep[voir respectivement les chapitres 3.6, 3.10 et 3.7 ]{bedau2000openproblemsinartificiallife}.
Pour le chercheur en RE maîtriser ces systèmes \emph{open-ended} et concevoir des populations dans lesquelles l'évolution serait \emph{dirigée par l'environnement} permettrait de bénéficier des avantages habituellement recherchés par les techniques évolutionnaires classiques (auto-adaptation et design automatique) tout en s'affranchissant de la nécessité de connaître \emph{a priori} les comportements recherchés et les environnements dans lesquels ils évolueront. C'est aussi pour nous la possibilité de rapprocher biologie et RE afin d'assurer une plus grande proximité entre le modèle robotique et l'objet biologique qu'il doit nous permettre d'étudier.

Pour implémenter cette évolution \emph{open-ended} et \emph{dirigée par l'environnement} sur des groupes de robots \cite{bredeche11mcmds} ont conçu un algorithme qu'ils appellent mEDEA (pour \emph{minimal Environment-Driven Distributed Evolutionary Adaptation}), qui reprend bon nombre d'éléments des algorithmes de \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots}.

Cet algorithme tourne en continue sur chaque robot d'une population de robot, parallèlement à une fonction de communication dont le but est de recevoir et stocker les génomes dans une liste de \emph{génomes importés}.

À chaque instant, le comportement d'un agent donné est déterminé par une architecture de contrôle dont les paramètres sont stockés (encodés) dans un \emph{génome actif}, qui restera le même toute la durée d'une génération. Ce génome est émis en continu par la fonction de communication, dans la limite imposée par le rayon d'émission du robot. Ce génome consiste dans les faits à une liste de nombres entiers qui encode les paramètres d'un réseau de neurones (bien qu'il pourrait s'agir de n'importe quelle autre architecture de contrôle).

De fait cet algorithme implémente un certain nombre de caractéristiques simples mais néanmoins importantes de la structure traditionnelle des algorithmes évolutionnaires:

\textbf{Un opérateur de sélection }: que les auteurs veulent minime afin de garantir l'\emph{open-endness} de l'expérience. C'est une simple sélection aléatoire d'un génome parmi la liste des génomes importés. Il n'y a aucune pression de sélection au \emph{niveau local de l'individu}. Du point de vue de ce dernier, la sélection se fait totalement aléatoirement. Aucune entité centrale et aucune connaissance quelconque n'est nécessaire pour sélectionner le génome qui sera utilisé à la prochaine génération. La pression à la sélection n'est perceptible qu'à \emph{un niveau global},\emph{de la population}: plus un génome est distribué à un grand nombre d'individus, plus il se propage dans la population, plus il a de chance d'être sélectionné aléatoirement à la génération suivante \emph{en moyenne} dans l'ensemble de la population. Il s'en suit que plus larges sont les populations et les chances de croisements (au sens de rencontre et non génétique) entre les individus, plus précise et plus efficace sera la pression de sélection au niveau de la population.

\textbf{Un opérateur de variation (mutation)}: que les auteurs choisissent comme conservateur, afin d'assurer une continuité tout au long de la course évolutionnaire. Générer des copies modifiées d'un génome ne fait sens que s' il existe une continuité dans la généalogie de ce génome : s' il n'y a pas de variation l'algorithme finira par converger en moyenne vers la solution la plus efficace au sein de la population initiale, s' il y a trop de mutations il n'y aura pas d'évolution non plus. Nous avons déjà discuté de cette propriété d'un point de vue biologique dans les cadres des espaces de \cite{godfrey2009darwinian} (cf. section \ref{sec:pgs}) et il est intéressant de voir comme les réflexions des chercheurs en RE font souvent écho à celles des biologistes. Si dans leurs expériences de RE les auteurs optent pour un opérateur très faible (conservateur, qui agit peu) pour des raisons pratiques et pour assurer l'émergence de solutions correctes, il n'en demeure pas moins qu'il est possible de le faire varier et d'observer la réaction du système en conséquence. On conçoit très bien comment ce type d'expériences pourrait être reprise pour explorer les espaces des populations darwiniennes de PGS (en faisant, dans ce cas, se déplacer la population le long de l'axe C de l'espace).

\textbf{Un opérateur de remplacement}: comme nous l'avons évoqué dans la section précédente, procéder à une véritable reproduction en RE est impossible, au sens ou le partage de matériel physique est encore trop complexe. C'est pourquoi lorsque les chercheurs de RE s'appliquent à faire de l'évolution embarquée, ils choisissent plutôt d'exécuter un opérateur de remplacement. Ce dernier va décider de la <<\,mort\,>>, de la disparition des génomes remplacés. Ce remplacement se fait par (1) une délétion du génome actif, et (2), une sélection d'un génome au hasard dans la liste des génomes. Au niveau de la population, cela implique que les génomes survivants à une génération $G$ ont de fortes chances d'être corrélés avec des stratégies efficaces capables de favoriser les rencontres. En effet un génome donné ne peut survivre qu'à travers des copies légèrement différentes de lui même transmises à d'autres robots tout au long de l'expérience. C'est pourquoi les contrôleurs capable de maximiser les rencontres avec d'autres robots, et donc de maximiser le nombre de transmissions de son génome, surviveront à la génération suivante. Une des conséquences de cette définition de l'opérateur fait que, si à la fin d'une génération, un robot n'a pu recevoir de génomes (ou dit autrement, si un génome n'a pas été en mesure de contrôler un robot pour lui permettre de recevoir d'autres génomes) et que  sa liste de génomes importés est donc vide, le robot ne sera plus en mesure de se déplacer. Il est ainsi mis en mode <<\,pause\,>>, et ne fait qu'<<\,écouter\,>>.

Ainsi, les génomes qui fournissent au robot le plus de chances de rencontrer beaucoup d'autres robots auront plus de chances d'être sélectionnés par la suite et d'être transmis aux générations suivantes. La ``fonction fitness'' ne disparaît pas totalement mais est entièrement implicite et dépend de l'environnement et des capacité des robots.

Ce protocole expérimental accentue beaucoup le caractère \emph{open ended} des expériences qu'il génère, notamment grâce à son opérateur de sélection totalement aléatoire. De ce point de vu l'algorithme mEDEA est vraiment au croisement entre les \emph{modèles conceptuels} de Vie Artificielle dont nous avons parlé dans la section \ref{sec:cmpdr:va} et la Robotique \'Evolutionnaire. En ce sens il réalise parfaitement le rapprochement souhaité par \cite{watson02embodiedevolutiondistributingevolutionaryalgorithmpopulationrobots}. C'est une expérience de Vie Artificielle à part entière dans le sens où l'intervention de l'homme dans le processus évolutif est minime et que le but est d'obtenir un système totalement autonome le plus proche de ce que la vie a pu produire ; et c'est aussi une expérience de Robotique \'Evolutionnaire dans le sens où elle veut produire des comportement pratique et utile pour des robots en appliquant une évolution totalement incarnée dans le monde physique réel à l'intérieur des robots.

Avec cette méthode les auteurs ont pu obtenir d'intéressants résultats, qu'ils ont résumés dans : \cite{bredeche2012environmentdrivenopenende}. Ils  ont montré à travers un certain nombre d'expériences qu'en appliquant ces protocoles il était possible de faire évoluer des populations de robots capable de suivre un consensus, d'obtenir une population qui peut s'adapter (en évoluant) à des changements environnementaux, de développer des comportements altruistes ou encore d'obtenir des sous-groupes spécialisés lorsque cela est nécessaire.


\section{Conclusion}

La Robotique \'Evolutionnaire tel que pensée par \cite{bredeche2012environmentdrivenopenende} combine les points forts de nombreux éléments traditionnels utilisés par les chercheurs en biologie pour étudier la théorie de l'évolution. En ce sens cette méthode est une méthode privilégiée pour étudier l'évolution. Elle permet, tout comme les expériences de pensée, de proposer des preuves conceptuelles de la faisabilité ou de l'incohérence de certaines hypothèses. Tout comme la sélection artificielle, elle offre au scientifique la possibilité d'observer des génomes de sélection et d'évolution à des échelles humaines et compréhensibles tout en assurant l'enregistrement de toutes les étapes et paramètres de. ?
Dans ce chapitre nous avons rapidement présenté quelques méthodes souvent utilisées par les chercheurs pour étudier la théorie de l'évolution et essayer de résoudre les problèmes qu'elle génère. Nous avons d'abord parlé de la sélection artificielle et de son utilisation par Darwin puis par d'autres. Nous avons brièvement parlé des expériences de pensée pour ensuite nous attarder plus longuement sur les modèles et simulations informatiques.

Nous avons essayé de dégager certains avantages et inconvénients de ces simulations, en essayant de justifier leur utilisation au même titre que des expériences traditionnelles.

Nous avons ensuite présenté en détails la Robotique \'Evolutionnaire, certains problèmes qu'elle rencontre et certaines de ces extensions actuelles. Nous avons insisté sur les approches embarquées et<<\,\emph{open ended}\,>> parmi les orientations actuelles prisent par les chercheurs de la discipline. Ces approches nous semblent les plus intéressantes car les plus aptes à modéliser des problèmes biologiques et à les résoudre. Elles réunissent les points forts des différents domaines et méthodes qui les inspirent et ont en ce sens de nombreuses propriétés.
